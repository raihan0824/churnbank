# -*- coding: utf-8 -*-
"""Churn_Bank.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1anBJkoHGKTpwmqgihlTDiyXPFfYvi3l4
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import statsmodels.api as sm
from sklearn.preprocessing import StandardScaler
!pip install pandasql
from pandasql import sqldf
from sklearn.model_selection import train_test_split

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix
from sklearn import tree
from sklearn.ensemble import RandomForestClassifier

df = pd.read_csv("/content/churn.csv")

df

"""## Data Exploration"""

df[df['CustomerId'].duplicated(keep=False)]

"""We can see that Customerid column has no duplicate"""

total_germany = len(df.loc[df['Geography'].str.contains('Germany')].Exited)
total_france = len(df.loc[df['Geography'].str.contains('France')].Exited)
total_spain = len(df.loc[df['Geography'].str.contains('Spain')].Exited)

total_male = len(df.loc[df['Gender'].str.contains('Male')].Exited)
total_female = len(df.loc[df['Gender'].str.contains('Female')].Exited)

total_hascrcard_0 = len(df.loc[df['HasCrCard'] == 0].Exited)
total_hascrcard_1 = len(df.loc[df['HasCrCard'] == 1].Exited)

total_activemember_0 = len(df.loc[df['IsActiveMember'] == 0].Exited)
total_activemember_1 = len(df.loc[df['IsActiveMember'] == 1].Exited)

fig, sty = plt.subplots(2, 2, figsize=(15, 8))

total1 = [total_france,total_spain,total_germany]
ax1 = sns.countplot(data = df, x='Geography', hue='Exited',ax=sty[0][0])
patches1 = ax1.patches[3:6]
for p,total in zip(patches1,total1):
    percentage = '{:.1f}%'.format(100 * p.get_height()/total)
    x = p.get_x() + p.get_width()
    y = p.get_height()
    ax1.annotate(percentage, (x, y),ha='right')

total2 = [total_female,total_male]
ax2 = sns.countplot(data = df, x='Gender', hue = 'Exited', ax = sty[0][1])
patches2 = ax2.patches[2:4]
for p,total in zip(patches2,total2):
    percentage = '{:.1f}%'.format(100 * p.get_height()/total)
    x = p.get_x() + p.get_width()
    y = p.get_height()
    ax2.annotate(percentage, (x, y),ha='right')
    
total3 = [total_hascrcard_0,total_hascrcard_1]
ax3 = sns.countplot(data = df, x='HasCrCard', hue = 'Exited',ax = sty[1][0])
patches3 = ax3.patches[2:4]
for p,total in zip(patches3,total3):
    percentage = '{:.1f}%'.format(100 * p.get_height()/total)
    x = p.get_x() + p.get_width()
    y = p.get_height()
    ax3.annotate(percentage, (x, y),ha='right')
    
total4 = [total_activemember_0,total_activemember_1]
ax4 = sns.countplot(data = df, x='IsActiveMember', hue = 'Exited', ax = sty[1][1])
patches4 = ax4.patches[2:4]
for p,total in zip(patches4,total4):
    percentage = '{:.1f}%'.format(100 * p.get_height()/total)
    x = p.get_x() + p.get_width()
    y = p.get_height()
    ax4.annotate(percentage, (x, y),ha='right')

plt.show()

"""We can see that:
> The customer in Germany, the female customer, and the customer that's not an active member is more likely to churn

### Balance & Salary

Initial Hypothesis:
> If the ratio between balance and salary is high, it means that the customer fill most of their salary to their balance account and more likely to stay
"""

df['Bal_Sal_Ratio'] = df['Balance']/df['EstimatedSalary']

sqldf('SELECT Balance,EstimatedSalary as Salary,Bal_Sal_Ratio from df')

sns.catplot(x="Exited", y="Bal_Sal_Ratio", jitter=False, data=df)

"""It's very absurd to see the outlier above, and then the cause will be analyzed"""

sqldf("SELECT * FROM df WHERE Bal_Sal_Ratio>100 ORDER BY Bal_Sal_Ratio DESC")

"""There are people who have a high balance in their account but have a very low salary. It can be said that this kind of people fill their balance account with other things such as credit or passive income, or maybe the bank gives a poor estimate on the customer's salary.

**Missing Information** :
1. Customer's job or income
2. How the bank estimated the customer's salary (it's clearly not based on the balance)

### Age & Tenure

Initial hypothesis:
> 1. The customer that has a long tenure are more likely to stay
2. The customer who started at an old age are more likely to stay
"""

sorted(df['Tenure'].unique())

Dict_tenure = {}

for i in range(0,11):
    Dict_tenure[f"total_tenure_{i}"] = len(df[df["Tenure"] == i])
    
Dict_tenure

fig = plt.subplots(figsize=(15, 8))
total = list(Dict_tenure.values())
ax = sns.countplot(data = df, x='Tenure', hue = 'Exited')
patches = ax.patches[11:22]
for p,total in zip(patches,total):
    percentage = '{:.1f}%'.format(100 * p.get_height()/total)
    x = p.get_x() + p.get_width()
    y = p.get_height()
    ax.annotate(percentage, (x, y),ha='right')

"""We can see that customer's tenure doesn't really affect whether customer will churned or not"""

df['age_start'] = df['Age'] - df['Tenure']

dfc = df.copy()
dfc['age_start_40_50'] = dfc['age_start'].apply(lambda x: 1 if x > 40 and x<50 else 0)
dfc['age_start_50_60'] = dfc['age_start'].apply(lambda x: 1 if x > 50 and x<60 else 0)
dfc['age_start_60_70'] = dfc['age_start'].apply(lambda x: 1 if x > 60 and x<70 else 0)
dfc['age_start_>_70'] = dfc['age_start'].apply(lambda x: 1 if x > 70 else 0)
dfc['age_start_<_40'] = dfc['age_start'].apply(lambda x: 1 if x < 40 else 0)

dfc['age_start_range'] = dfc['age_start'].apply(lambda x: 'age_start_40_50' if x > 40 and x<50 
                                               else 'age_start_50_60' if x > 50 and x<60
                                               else 'age_start_60_70' if x > 60 and x<70
                                               else 'age_start_>_70' if x > 70
                                               else 'age_start_<_40')

dict_age = {}
age_range = ['<40','40_50','50_60','60_70','>70']
age_column = ['age_start_<_40','age_start_40_50','age_start_50_60','age_start_60_70','age_start_>_70']
for i,age in zip(age_range,age_column):
    dict_age[f"total_exited_{i}"] = len(dfc[dfc[age] ==1])
    
dict_age

fig = plt.subplots(figsize=(15, 8))
total = list(dict_age.values())
ax = sns.countplot(data = dfc, x='age_start_range', hue = 'Exited')
patches = ax.patches[5:10]
for p,total in zip(patches,total):
    percentage = '{:.1f}%'.format(100 * p.get_height()/total)
    x = p.get_x() + p.get_width()
    y = p.get_height()
    ax.annotate(percentage, (x, y),ha='right')

print(sqldf("SELECT COUNT(Exited) as age_start_40_50, Exited from dfc where age_start_40_50=1 group by exited"))
print(sqldf("SELECT COUNT(Exited) as age_start_50_60, Exited from dfc where age_start_50_60=1 group by exited"))
print(sqldf("SELECT COUNT(Exited) as age_start_60_70, Exited from dfc where age_start_60_70=1 group by exited"))

"""> As we can see, the customer who started at between age 40 to 60 are more than likely to churn, this is counterintuitive to the initial hypothesis.

### Country
"""

total1 = [total_france,total_spain,total_germany]
ax1 = sns.countplot(data = df, x='Geography', hue='Exited')
patches1 = ax1.patches[3:6]
for p,total in zip(patches1,total1):
    percentage = '{:.1f}%'.format(100 * p.get_height()/total)
    x = p.get_x() + p.get_width()
    y = p.get_height()
    ax1.annotate(percentage, (x, y),ha='right')
    
plt.show()

sqldf("SELECT AVG(Balance) as Average_Balance, Geography from df GROUP BY Geography ORDER BY AVG(Balance) DESC")

sqldf("SELECT AVG(EstimatedSalary) as AVG_Salary, Geography from df GROUP BY Geography ORDER BY AVG(EstimatedSalary) DESC")

sqldf("SELECT COUNT(Exited) as Count_Exited, Geography from df WHERE Exited=1 GROUP BY Geography ORDER BY COUNT(Exited) DESC")

"""We can see that even though Germany is the richest country in this data, they have the most costumer exit.

## Data Preparation

### 1. Clean useless column & check NA Values
"""

list(df)

# drop columns that have no use
df1 = df.drop(["RowNumber","CustomerId","Surname"], axis=1)

df1.isna().sum()

"""### 2. Feature Engineering"""

{column: list(df1[column].unique()) for column in df1.select_dtypes('object').columns}

"""*Geography* will be one hot encoded and *Gender* will be binary encoded"""

def binary_encode(df, column, positive_value):
    df = df.copy()
    df[column] = df[column].apply(lambda x: 1 if x == positive_value else 0)
    return df

def onehot_encode(df, column, prefix):
    df = df.copy()
    dummies = pd.get_dummies(df[column], prefix=prefix)
    df = pd.concat([df, dummies], axis=1)
    df = df.drop(column, axis=1)
    return df

pd.get_dummies(df1["Geography"])

def encode(df):
    df = df.copy()
    
    # Encode Gender column
    df = binary_encode(df, 'Gender', positive_value='Male')
    
    # Encode Geography column
    df = onehot_encode(df, 'Geography', prefix='Country')
    
    return df

df1 = encode(df1)
df1

"""### 3. Multivariate Analysis"""

corr = df1.corr()

plt.figure(figsize=(12, 10))
sns.heatmap(corr, annot=True, vmin=-1.0, cmap='mako')
plt.show()

"""- We can see that the only country that has positive correlation value with Balance and Estimated Salary is Germany. That means basically people in Germany are richer than people in Spain and France
- The bank have a poor judgement in giving Credit Score, as the correlation between *Exited* and *CreditScore* is very low
- Correlation between country variables is considerably high, therefore for glm model, country variables will be removed to prevent multicollinearity
"""

corr_germany = df1.loc[df1['Country_Germany']==1].drop(['Country_France','Country_Spain','Country_Germany'],1).corr()

plt.figure(figsize=(12, 10))
sns.heatmap(corr_germany, annot=True, vmin=-1.0, cmap='mako')
plt.title('Correlation plot for Germany')
plt.show()

corr_spain = df1.loc[df1['Country_Spain']==1].drop(['Country_France','Country_Spain','Country_Germany'],1).corr()

plt.figure(figsize=(12, 10))
sns.heatmap(corr_spain, annot=True, vmin=-1.0, cmap='mako')
plt.title('Correlation plot for Spain')
plt.show()

corr_france = df1.loc[df1['Country_France']==1].drop(['Country_France','Country_Spain','Country_Germany'],1).corr()

plt.figure(figsize=(12, 10))
sns.heatmap(corr_france, annot=True, vmin=-1.0, cmap='mako')
plt.title('Correlation plot for France')
plt.show()

"""### 4. Data Cleansing"""

outlier_plot = ["CreditScore","Age","Tenure","Balance","NumOfProducts","EstimatedSalary"]
for i in outlier_plot:
    sns.boxplot(x = df1[i])
    plt.show()

"""We can see that CreditScore, Age, NumOfProducts have outliers"""

def outlier_cleaner(df,column):
    q1 = df[column].quantile(0.25)
    q3 = df[column].quantile(0.75)
    iqr = q3 - q1
    lower_boundary = q1 - 1.5 * iqr
    upper_boundary = q3 + 1.5 * iqr
    cleaned_data = df.loc[(df[column] > lower_boundary) & (df[column] < upper_boundary)]
    return cleaned_data

def clean_outlier_columns(df):
    df = df.copy()
    
    # Clean outliers in CreditScore column
    df = outlier_cleaner(df,'CreditScore')
    
    # Clean outliers in Age column
    df = outlier_cleaner(df,'Age')
    
    # Clean outliers in NumOfProducts column
    df = outlier_cleaner(df,'NumOfProducts')
    
    return df

df_cleaned = clean_outlier_columns(df1)

print(df1.shape)
print(df_cleaned.shape)

"""### 5. Feature Scaling"""

def splitter(df):
    # Split df into X and y
    y = df['Exited'].copy()
    X = df.drop('Exited', axis=1).copy()
    
    # Scale X with a standard scaler
    #scaler = StandardScaler()
    #X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)
    
    return X, y

X, y = splitter(df_cleaned)

X

"""## Modelling"""

X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)

"""### Dealing with imbalanced dataset
> Balancing the data is necessary, otherwise the model will perform badly
"""

y_train.value_counts()

# SMOTE
from imblearn.over_sampling import SMOTE
X_train_SMOTE, y_train_SMOTE = SMOTE().fit_resample(X_train, y_train)

# Random Undersampling
from imblearn.under_sampling import RandomUnderSampler
undersample = RandomUnderSampler(sampling_strategy='majority')
X_train_under, y_train_under = undersample.fit_resample(X_train, y_train)

"""### Decision Tree

#### Using SMOTE
"""

dctree = DecisionTreeClassifier(max_depth =3, random_state = 42)
dctree_SMOTE = dctree.fit(X_train_SMOTE,y_train_SMOTE)

plt.figure(figsize=(30,10))
a = tree.plot_tree(dctree_SMOTE,
                   feature_names = list(X),
                   class_names = ['Churned','Retained'],
                   rounded = True,
                   filled = True,
                   fontsize=14)

plt.show()

pred_dctree_SMOTE = dctree_SMOTE.predict(X_test)

print(metrics.classification_report(y_test, pred_dctree_SMOTE))
print("ROC AUC score for oversampled SMOTE data: ", roc_auc_score(y_test, pred_dctree_SMOTE))

"""#### Using Random Undersampling"""

dctree_under = dctree.fit(X_train_under,y_train_under)

pred_dctree_under = dctree_under.predict(X_test)
print(metrics.classification_report(y_test, pred_dctree_under))
print("ROC AUC score for Undersampled data: ", roc_auc_score(y_test, pred_dctree_under))

"""> Because for the Undersampled data ROC AUC score and F1 score is higher, then for parameter tuning, Undersampled data will be used

#### Parameter Tuning
"""

from sklearn.model_selection import GridSearchCV
tuned_parameters = [{'max_depth': list(range(1,10)), 
                     'min_samples_split': list(range(2,10))}]
scores = ['f1']

for score in scores:
    
    print()
    print(f"Tuning hyperparameters for {score}")
    print()
    
    clf = GridSearchCV(
        DecisionTreeClassifier(), tuned_parameters,
        scoring = f'{score}'
    )
    clf.fit(X_train_under, y_train_under)
    
    print("Best parameters set:")
    print()
    print(clf.best_params_)

clf.best_params_['min_samples_split']

dctree_optimal = DecisionTreeClassifier(max_depth =clf.best_params_['max_depth'], min_samples_split=clf.best_params_['min_samples_split'], random_state = 42)
dctree_optimal = dctree_optimal.fit(X_train_under,y_train_under)
pred_dctree_optimal = dctree_optimal.predict(X_test)
print(metrics.classification_report(y_test, pred_dctree_optimal))
print("ROC AUC score for Optimal model: ", roc_auc_score(y_test, pred_dctree_optimal))

plt.figure(figsize=(40,30))
a = tree.plot_tree(dctree_optimal,
                   feature_names = list(X),
                   class_names = ['Churned','Retained'],
                   rounded = True,
                   filled = True,
                   fontsize=14)

plt.show()

"""### Random Forest

#### SMOTE
"""

rf_SMOTE = RandomForestClassifier(bootstrap = True, max_features = 'sqrt')
rf_SMOTE.fit(X_train_SMOTE, y_train_SMOTE)
pred_rf_SMOTE = rf_SMOTE.predict(X_test)
print(metrics.classification_report(y_test, pred_rf_SMOTE))
print("ROC AUC score for SMOTE data: ", roc_auc_score(y_test, pred_rf_SMOTE))

"""#### Random Undersampling"""

rf_under = RandomForestClassifier(bootstrap = True, max_features = 'sqrt')
rf_under.fit(X_train_under, y_train_under)
pred_rf_under = rf_under.predict(X_test)
print(metrics.classification_report(y_test, pred_rf_under))
print("ROC AUC score for Undersampled data: ", roc_auc_score(y_test, pred_rf_under))

"""> Because for the SMOTE data F1 score is higher even though ROC AUC score is lower, then for parameter tuning, SMOTE data will be used

#### Parameter Tuning
"""

from sklearn.model_selection import GridSearchCV
tuned_parameters_rf = [{'n_estimators': [100,300,500], 
                       'max_depth': [3,5,7],
                       'max_features': [3,5,7]}]
scores = ['f1']

for score in scores:
    
    print()
    print(f"Tuning hyperparameters for {score}")
    print()
    
    clf = GridSearchCV(
        RandomForestClassifier(), tuned_parameters_rf,
        scoring = f'{score}'
    )
    clf.fit(X_train_SMOTE, y_train_SMOTE)
    
    print("Best parameters set:")
    print()
    print(clf.best_params_)

clf.best_params_['max_depth']

rf_optimal = RandomForestClassifier(bootstrap = True, max_features = clf.best_params_['max_features'], max_depth = clf.best_params_['max_depth'],random_state=300)
rf_optimal.fit(X_train_SMOTE, y_train_SMOTE)
pred_rf_optimal = rf_optimal.predict(X_test)
print(metrics.classification_report(y_test, pred_rf_optimal))
print("ROC AUC score for optimal model: ", roc_auc_score(y_test, pred_rf_optimal))

"""#### Feature Importance"""

# Feature Importance
from matplotlib import pyplot
importance_rf = rf_optimal.feature_importances_
features=df_cleaned.columns
indices = np.argsort(importance_rf)

plt.figure(1)
plt.title('Feature Importances')
plt.barh(range(len(indices)), importance_rf[indices], color='b', align='center')
plt.yticks(range(len(indices)), features[indices])
plt.xlabel('Relative Importance')

"""### Logistic Regression

#### Removing multicollinearity variables
"""

list(X)

delvar = ['Country_Spain','age_start','Country_France']

X_train_log = X_train.drop(delvar,1)
X_test_log = X_test.drop(delvar,1)

"""#### Balancing the data"""

# SMOTE
from imblearn.over_sampling import SMOTE
X_train_log_SMOTE, y_train_SMOTE = SMOTE().fit_resample(X_train_log, y_train)

# Random Undersampling
from imblearn.under_sampling import RandomUnderSampler
undersample = RandomUnderSampler(sampling_strategy='majority')
X_train_log_under, y_train_under = undersample.fit_resample(X_train_log, y_train)

logreg = LogisticRegression()
logreg = logreg.fit(X_train_log, y_train)
pred_log = logreg.predict(X_test_log)
print(metrics.classification_report(y_test, pred_log))
print("ROC AUC score for optimal model: ", roc_auc_score(y_test, pred_log))

"""#### SMOTE"""

logreg_SMOTE = logreg.fit(X_train_log_SMOTE, y_train_SMOTE)
pred_log_SMOTE = logreg.predict(X_test_log)
print(metrics.classification_report(y_test, pred_log_SMOTE))
print("ROC AUC score for optimal model: ", roc_auc_score(y_test, pred_log_SMOTE))

"""#### Random Undersampling"""

logreg_under = logreg.fit(X_train_log_under, y_train_under)
pred_log_under = logreg.predict(X_test_log)
print(metrics.classification_report(y_test, pred_log_under))
print("ROC AUC score for optimal model: ", roc_auc_score(y_test, pred_log_under))

"""# Model Conclusion"""

models = [pred_dctree_optimal,pred_rf_optimal,pred_log_SMOTE]
model_names = [
    "         Decision Tree F1 Score",
    "         Random Forest F1 Score",
    "   Logistic Regression F1 Score",
]

for model, name in zip(models, model_names):
    print(name + ": {}".format(metrics.f1_score(y_test, model)))

"""> 1. The best model is Random Forest with F1 as the metric
2. The most important variables to predict churned customer is Age, IsActiveMember, NumOfProducts
"""